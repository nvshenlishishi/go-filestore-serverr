## 7-1 Ceph是什么
### Ceph简介
- Ceph是什么
- Ceph主要用于解决什么问题
- Ceph的历史与现状
### Ceph的特点
- 部署简单
- 可靠性高
- 性能高
- 分布式，可扩展性
- 客户端支持多语言
- 开源

### Ceph体系架构
``` 
APP   Host/VM Client      使用者
       OBJ BLOCK FILE      存储类型
       RGW RBD CEPHFS      应用接口层
LIBRADOS          低阶接口层
RADOS             底层存储系统
```
## 7-2 Ceph集群介绍及兼容亚马逊S3接口详解
### Ceph基础组件
- OSD: 用于集群中所有数据与对象的存储：存储/复制/平衡/恢复数据等等
- Monitor: 监控集群状态，维护cluster MAP表，保证集群数据一致性
- MDS: 保存文件系统服务的元数据(OBJ/Block不需要该服务)
- GW: 提供与Amazon S3和Swift兼容的Restful API的gateway服务

### AWS S3术语
- Region: 存储数据所在的地理区域
- Endpoint: 存储服务入口，Web服务入口点的URL
- Bucket: 存储桶是S3中用于存储对象的容器
- Object: 对象是S3中存储的基本实体，由对象数据和元数据组成
- Key: 键是存储桶中对象的唯一标识符，桶内的每个对象都只能有一个key

## 7-3 编码实战: Go访问管理Ceph集群
### 服务架构变迁
- 1. 用户->传输服务
- 2. 传输服务->唯一文件表 && 用户文件表
- 3. 传输服务->本地存储
- 4. 传输服务->Hash计算 && Redis缓存
- 5. 传输服务->Ceph集群
- ceph_conn.go
- 生成Ceph key secret
``` 
docker exec -it gwnode radosgw-admin user create --uid=user1 --display-name=user1
```
- test_ceph.go
```go
package main

import (
	"fmt"
	"go-filestore-server/database/ceph"
	"os"
)

func main() {
	bucket := ceph.GetCephBucket("userfile")

	d, _ := bucket.Get("/ceph/866cc7c87c9b612dd8904d2c5dd07d6f6c22b834")
	tmpFile, _ := os.Create("/tmp/test_file")
	tmpFile.Write(d)
	return

	// // 创建一个新的bucket
	// err := bucket.PutBucket(s3.PublicRead)
	// fmt.Printf("create bucket err: %v\n", err)

	// 查询这个bucket下面指定条件的object keys
	res, _ := bucket.List("", "", "", 100)
	fmt.Printf("object keys: %+v\n", res)

	// // 新上传一个对象
	// err = bucket.Put("/testupload/a.txt", []byte("just for test"), "octet-stream", s3.PublicRead)
	// fmt.Printf("upload err: %+v\n", err)

	// // 查询这个bucket下面指定条件的object keys
	// res, err = bucket.List("", "", "", 100)
	// fmt.Printf("object keys: %+v\n", res)
} 
```
## 7-4 编码实战: Go实现Ceph的文件上传下载+小结
### 本周小结
- Ceph基础概念及应用场景
- Ceph基础原理及部署
- 代码实践及改造原有上传接口

## 7-5 Ubuntu下通过Docker快速搭建Ceph测试集群

``` 
# 要用root用户创建，或者有sudu权限
# 建议使用这个docker镜像源: https://registry.docker-cn.com
# 1.修改docker镜像源
cat > /etc/docker/daemon.json << EOF
{
    "registry-mirrors":[
        "https://registry.docker-cn.com"
    ]
}
EOF

## 重启docker
systemctl restart docker


# 链接：https://www.imooc.com/article/282861
# 1. 创建Ceph专用网络
docker network create --driver bridge --subnet 172.20.0.0/16 ceph-network
docker network inspect ceph-network
# 2. 删除旧的ceph相关容器
docker rm -f $(docker ps -a | grep ceph | awk '{print $1}')
# 3. 清理旧的ceph相关目录文件，加入有的话
rm -rf /www/ceph /var/lib/ceph/  /www/osd/
# 4. 创建相关目录及修改权限，用于挂载volume
mkdir -p /www/ceph /var/lib/ceph/osd /www/osd/
chown -R 64045:64045 /var/lib/ceph/osd/
chown -R 64045:64045 /www/osd/
# 5. 创建monitor节点
docker run -itd --name monnode --network ceph-network --ip 172.20.0.10 -e MON_NAME=monnode -e MON_IP=172.20.0.10 -v /www/ceph:/etc/ceph ceph/mon
# 6. 在monitor节点上标识3个osd节点
docker exec monnode ceph osd create
docker exec monnode ceph osd create
docker exec monnode ceph osd create

# 7. 创建OSD节点
docker run -itd --name osdnode0 --network ceph-network -e CLUSTER=ceph -e WEIGHT=1.0 -e MON_NAME=monnode -e MON_IP=172.20.0.10 -v /www/ceph:/etc/ceph -v /www/osd/0:/var/lib/ceph/osd/ceph-0 ceph/osd 
docker run -itd --name osdnode1 --network ceph-network -e CLUSTER=ceph -e WEIGHT=1.0 -e MON_NAME=monnode -e MON_IP=172.20.0.10 -v /www/ceph:/etc/ceph -v /www/osd/1:/var/lib/ceph/osd/ceph-1 ceph/osd
docker run -itd --name osdnode2 --network ceph-network -e CLUSTER=ceph -e WEIGHT=1.0 -e MON_NAME=monnode -e MON_IP=172.20.0.10 -v /www/ceph:/etc/ceph -v /www/osd/2:/var/lib/ceph/osd/ceph-2 ceph/osd
# 8. 增加monitor节点，组件成集群
docker run -itd --name monnode_1 --network ceph-network --ip 172.20.0.11 -e MON_NAME=monnode_1 -e MON_IP=172.20.0.11 -v /www/ceph:/etc/ceph ceph/mon
docker run -itd --name monnode_2 --network ceph-network --ip 172.20.0.12 -e MON_NAME=monnode_2 -e MON_IP=172.20.0.12 -v /www/ceph:/etc/ceph ceph/mon
# 9. 创建gateway节点
docker run -itd --name gwnode --network ceph-network --ip 172.20.0.9 -p 9080:80 -e RGW_NAME=gwnode -v /www/ceph:/etc/ceph ceph/radosgw
# 10. 查看ceph集群状态
sleep 10 && docker exec monnode ceph -s
```


